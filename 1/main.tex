\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage[shortlabels]{enumitem}

\DeclareMathOperator{\R}{\mathbb R}

\pagestyle{fancy}
\fancyhead[L]{Banghao Chi}
\fancyhead[C]{Homework 1}
\fancyhead[R]{25th Jan}

\fancyfoot[C]{\thepage}

\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

\begin{document}

\section*{Exercise 1}
(15 points) Find the global and local minimizers of the following functions. For each minimizer, state whether it is a strict global/local minimizer. (You do not need to explain your answers for this question.)

\begin{itemize}
    \item $f: [0,1] \to \mathbb{R}$, $f(x) = -(x-\frac{1}{3})^2$
    \item $f: [0,\infty) \to \mathbb{R}$, $f(x) = x$
    \item $f(x) = \lfloor|x|\rfloor$ ($f$ is the floor of the absolute value of $x$)
    \item $f: \mathbb{R} \to \mathbb{R}$, $f: (0,\infty) \to \mathbb{R}$ and $f(x) = \begin{cases} 
        k & \text{if } k \in \mathbb{Z} \text{ and } x = 2^k \\
        0 & \text{otherwise}
    \end{cases}$
\end{itemize}

\textbf{Solution:}

\begin{itemize}
    \item $f: [0,1] \to \mathbb{R}$, $f(x) = -(x-\frac{1}{3})^2$
    
    The strict global minimizer here is $x^* = 1$. The strict local minimizers here are $x^* = 0$ and $x^* = 1$, since we also consider the boundary point when determining local minimizers.
    \item $f: [0,\infty) \to \mathbb{R}$, $f(x) = x$
    
    The strict global minimizer here is $x^* = 0$. The strict local minimizer here is also $x^* = 0$, since we also consider the boundary point when determining local minimizers.
    \item $f(x) = \lfloor|x|\rfloor$ ($f$ is the floor of the absolute value of $x$)
    
    The global minimizers here are $x^* \in (-1, 1)$, but not strictly. The local minimizers here are $x^* \in (\mathbb{R} \setminus \mathbb{Z}) \cup \{0\}$, but not strictly.
    \item $f: \mathbb{R} \to \mathbb{R}$, $f: (0,\infty) \to \mathbb{R}$ and $f(x) = \begin{cases} 
        k & \text{if } k \in \mathbb{Z} \text{ and } x = 2^k \\
        0 & \text{otherwise}
    \end{cases}$

    There is no global minimizer here. The local minimizers here are $x^* \in (0, \infty) \setminus \{2^k \mid k \in \mathbb{Z}_{+}\}$, but not strictly.
\end{itemize}

\newpage

\section*{Exercise 2}
(10 points) Let $V$ be a vector space equipped with the field $\mathbb{R}$ and an inner product $\cdot: V \times V \to \mathbb{R}$, and let $\mathbf{u}, \mathbf{v} \in V$ be two vectors. Prove that $\mathbf{u} \cdot \mathbf{v} = 0$ if and only if $\|\mathbf{u}\| \leq \|\mathbf{u} + c\mathbf{v}\|$ for every real number $c \in \mathbb{R}$.

(Do not assume that $\cdot$ is the ordinary dot product.)

\textbf{Solution:}

In order to prove the statement, we need to show prove from both directions.

($\Rightarrow$) First, assume $\mathbf{u} \cdot \mathbf{v} = 0$. We need to prove that $\|\mathbf{u}\| \leq \|\mathbf{u} + c\mathbf{v}\|$ for all $c \in \mathbb{R}$.

Consider $\|\mathbf{u} + c\mathbf{v}\|^2$:
\begin{align*}
\|\mathbf{u} + c\mathbf{v}\|^2 &= (\mathbf{u} + c\mathbf{v}) \cdot (\mathbf{u} + c\mathbf{v}) \\
&= \|\mathbf{u}\|^2 + c(\mathbf{u} \cdot \mathbf{v}) + c(\mathbf{v} \cdot \mathbf{u}) + c^2\|\mathbf{v}\|^2 \\
&= \|\mathbf{u}\|^2 + 2c(\mathbf{u} \cdot \mathbf{v}) + c^2\|\mathbf{v}\|^2
\end{align*}

Since $\mathbf{u} \cdot \mathbf{v} = 0$, this simplifies to:
\[\|\mathbf{u} + c\mathbf{v}\|^2 = \|\mathbf{u}\|^2 + c^2\|\mathbf{v}\|^2\]

As $c^2\|\mathbf{v}\|^2 \geq 0$ for any $c \in \mathbb{R}$ (since norms are non-negative), we have:
\[\|\mathbf{u} + c\mathbf{v}\|^2 \geq \|\mathbf{u}\|^2\]

Taking the square root of both sides (which preserves inequality as both sides are non-negative):
\[\|\mathbf{u} + c\mathbf{v}\| \geq \|\mathbf{u}\|\]

($\Leftarrow$) Conversely, assume $\|\mathbf{u}\| \leq \|\mathbf{u} + c\mathbf{v}\|$ for all $c \in \mathbb{R}$.

This implies:
\[\|\mathbf{u}\|^2 \leq \|\mathbf{u} + c\mathbf{v}\|^2 \text{ for all } c \in \mathbb{R}\]

Expanding the right side:
\[\|\mathbf{u}\|^2 \leq \|\mathbf{u}\|^2 + 2c(\mathbf{u} \cdot \mathbf{v}) + c^2\|\mathbf{v}\|^2\]

Subtracting $\|\mathbf{u}\|^2$ from both sides:
\[0 \leq 2c(\mathbf{u} \cdot \mathbf{v}) + c^2\|\mathbf{v}\|^2\]

This is a quadratic in $c$. Therefore, there are two cases:
\begin{itemize}
    \item If $\|\mathbf{v}\|^2 = 0$, then the inequality is trivially true.
    \item If $\|\mathbf{v}\|^2 > 0$, this is an upward-opening parabola for $c \in \mathbb{R}$. We can find the vertex of the parabola $c^*$:
    $$
    c^* = -\frac{2(\mathbf{u} \cdot \mathbf{v})}{2\|\mathbf{v}\|^2} = -\frac{(\mathbf{u} \cdot \mathbf{v})}{\|\mathbf{v}\|^2}
    $$

    Plugging $c^*$ into the inequality:
    \begin{align*}
        0 &\leq 2c^*(\mathbf{u} \cdot \mathbf{v}) + c^{*2}\|\mathbf{v}\|^2 \\
        &= 2\left(-\frac{(\mathbf{u} \cdot \mathbf{v})}{\|\mathbf{v}\|^2}\right)(\mathbf{u} \cdot \mathbf{v}) + \left(-\frac{(\mathbf{u} \cdot \mathbf{v})}{\|\mathbf{v}\|^2}\right)^2\|\mathbf{v}\|^2 \\
        &= -\frac{2(\mathbf{u} \cdot \mathbf{v})^2}{\|\mathbf{v}\|^2} + \frac{(\mathbf{u} \cdot \mathbf{v})^2}{\|\mathbf{v}\|^2} \\
        &= -\frac{(\mathbf{u} \cdot \mathbf{v})^2}{\|\mathbf{v}\|^2}
    \end{align*}

    Since $(\mathbf{u} \cdot \mathbf{v})^2 \geq 0$ and $\|\mathbf{v}\|^2 > 0$, the only way that the inequality holds is if $(\mathbf{u} \cdot \mathbf{v})^2 = 0$, which means $\mathbf{u} \cdot \mathbf{v} = 0$.
\end{itemize}

Therefore, $\mathbf{u} \cdot \mathbf{v} = 0$ if and only if $\|\mathbf{u}\| \leq \|\mathbf{u} + c\mathbf{v}\|$ for all $c \in \mathbb{R}$.

\newpage

\section*{Exercise 3}
(15 points) Let $A$ be an $n \times n$ symmetric matrix. Suppose that $\mathbf{x}^T A\mathbf{x} > 0$ for every nonzero vector $\mathbf{x} \in \R^n$. Prove the following statements.
\begin{itemize}
    \item Every diagonal entry of $A$ is positive.
    \item Every eigenvalue of $A$ is positive.
    \item Let $S \subseteq \{1,\ldots,n\}$, and suppose that $B$ is an $|S| \times |S|$ matrix obtained from $A$ by deleting all rows and columns whose indices are not in $S$. Then, every eigenvalue of $B$ is positive.
\end{itemize}

\textit{It will help to remember the formula}
\[\mathbf{x}^T A\mathbf{x} = \sum_{i=1}^n \sum_{j=1}^n A_{ij}x_ix_j.\]

It will also help to remember that symmetric matrices have real eigenvalues.
(For an example of a matrix $B$ constructed from a matrix $A$ as described above,
suppose that $A = \begin{bmatrix}
1 & 2 & 3 & 4 \\
2 & 5 & 6 & 7 \\
3 & 6 & 8 & 9 \\
4 & 7 & 9 & 10
\end{bmatrix}$ and $S = \{1,3\}$. Then, we obtain $B$ from $A$
by deleting all rows except rows 1 and 3, and also deleting all columns except columns 1 and 3. This leaves us with the $2 \times 2$ matrix $B = \begin{bmatrix}
1 & 3 \\
3 & 8
\end{bmatrix}$.)

\textbf{Solution:}

\begin{itemize}
    \item Every diagonal entry of $A$ is positive.
    
    Plug basis vector $e_i$ into $x$, we have:
    \[
    e_i^T A e_i = a_{ii} > 0
    \]

    Therefore, every diagonal entry of $A$ is positive.

    \item Every eigenvalue of $A$ is positive.

    Suppose $\lambda$ is an eigenvalue of $A$. Then,
    \[
    Ax = \lambda x
    \]

    Left multiply both sides by $x^T$, we get:
    \[
    x^T A x = \lambda x^T x = \lambda \sum_{i=1}^n x_i^2 > 0
    \]

    Since $x^T A x > 0$ for all nonzero $x$, we have $\lambda > 0$.

    \item Let $S \subseteq \{1,\ldots,n\}$, and suppose that $B$ is an $|S| \times |S|$ matrix obtained from $A$ by deleting all rows and columns whose indices are not in $S$. Then, every eigenvalue of $B$ is positive.

We want to show that any eigenvalue of the submatrix \(B\) is strictly positive.

Suppose \(\lambda\) is an eigenvalue of \(B\) and let \(\mathbf{x} \in \mathbb{R}^{|S|}\)
be an eigenvector corresponding to \(\lambda\). Thus,
\[
B \mathbf{x} \;=\; \lambda \, \mathbf{x}.
\]

Construct a vector \(\mathbf{y} \in \mathbb{R}^n\) by
\[
y_i \;=\;
\begin{cases}
x_i, & \text{if } i \in S, \\
0,   & \text{if } i \notin S.
\end{cases}
\]
Clearly, \(\mathbf{y} \neq \mathbf{0}\) if \(\mathbf{x} \neq \mathbf{0}\).

Because \(B\) is the submatrix of \(A\) corresponding to the index set \(S\),
we have
\[
\mathbf{y}^T A \mathbf{y}
\;=\;
\mathbf{x}^T B \mathbf{x}.
\]
With the eigenvalue equation \(\mathbf{x}^T B \mathbf{x} = \lambda \, \mathbf{x}^T \mathbf{x}\),
we obtain
\[
\mathbf{y}^T A \mathbf{y}
\;=\;
\lambda \, \|\mathbf{x}\|^2 > 0
\]

Since \(\|\mathbf{x}\|^2 \ge 0\) and \(\mathbf{x} \neq 0\), we get \(\lambda > 0\).
Therefore, every eigenvalue of \(B\) is strictly positive.

\end{itemize}

\end{document}